{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copyright (c) 2021-2022, NVIDIA CORPORATION & AFFILIATES\n",
    "#\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "# import cupy as cp\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# import cuquantum\n",
    "# from cuquantum import cutensornet as cutn\n",
    "\n",
    "a = u'0'\n",
    "b = u'à'\n",
    "A = np.array([[1,2],[3,4]])\n",
    "B = np.array([[4,3],[2,1]])\n",
    "len(b)\n",
    "# print(a)\n",
    "# print(b)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m                 edge_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m biadjacency_matrix\n\u001b[0;32m---> 22\u001b[0m B \u001b[39m=\u001b[39m generate_biadjacency_matrix(\u001b[39m8\u001b[39;49m, \u001b[39m8\u001b[39;49m)\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(B)\n",
      "Cell \u001b[0;32mIn [6], line 17\u001b[0m, in \u001b[0;36mgenerate_biadjacency_matrix\u001b[0;34m(n, m)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mwhile\u001b[39;00m edge_count \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m     16\u001b[0m     i \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, n \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m     \u001b[39mif\u001b[39;00m biadjacency_matrix[i][j] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39;49msum(biadjacency_matrix[i, :]) \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m     18\u001b[0m         biadjacency_matrix[i][j] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     19\u001b[0m         edge_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/my_first_env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2298\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2295\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m   2296\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m-> 2298\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[1;32m   2299\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/miniconda3/envs/my_first_env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def generate_biadjacency_matrix(n, m):\n",
    "    biadjacency_matrix = np.zeros((n, m), dtype=int)\n",
    "    for i in range(n):\n",
    "        edge_count = 0\n",
    "        while edge_count < 3:\n",
    "            j = random.randint(0, m - 1)\n",
    "            if biadjacency_matrix[i][j] == 0 and np.sum(biadjacency_matrix[:, j]) < 3:\n",
    "                biadjacency_matrix[i][j] = 1\n",
    "                edge_count += 1\n",
    "    for j in range(m):\n",
    "        edge_count = 0\n",
    "        while edge_count < 3:\n",
    "            i = random.randint(0, n - 1)\n",
    "            if biadjacency_matrix[i][j] == 0 and np.sum(biadjacency_matrix[i, :]) < 3:\n",
    "                biadjacency_matrix[i][j] = 1\n",
    "                edge_count += 1\n",
    "    return biadjacency_matrix\n",
    "\n",
    "B = generate_biadjacency_matrix(8, 8)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Constraints neighbors are :\n",
      "[[1, 0, 2], [1, 5, 4], [5, 1, 4], [6, 0, 7], [2, 4, 5], [6, 0, 3], [7, 6, 3], [2, 3, 7]]\n",
      "Variable neighbors are :\n",
      "[[5, 0, 3], [0, 1, 2], [4, 7, 0], [6, 7, 5], [4, 2, 1], [1, 2, 4], [5, 3, 6], [3, 6, 7]]\n",
      "--------\n",
      "0, [9, 8, 10]\n",
      "1, [9, 13, 12]\n",
      "2, [13, 9, 12]\n",
      "3, [14, 8, 15]\n",
      "4, [10, 12, 13]\n",
      "5, [14, 8, 11]\n",
      "6, [15, 14, 11]\n",
      "7, [10, 11, 15]\n",
      "8, [5, 0, 3]\n",
      "9, [0, 1, 2]\n",
      "10, [4, 7, 0]\n",
      "11, [6, 7, 5]\n",
      "12, [4, 2, 1]\n",
      "13, [1, 2, 4]\n",
      "14, [5, 3, 6]\n",
      "15, [3, 6, 7]\n",
      "ĉĈĊ,ĉčČ,čĉČ,ĎĈď,ĊČč,ĎĈċ,ďĎċ,Ċċď,ąĀă,ĀāĂ,ĄćĀ,Ććą,ĄĂā,āĂĄ,ąăĆ,ăĆć\n",
      "(['\\n', '\\t', '\\x0b'], ['\\n', '\\x0e', '\\r'], ['\\x0e', '\\n', '\\r'], ['\\x0f', '\\t', '\\x10'], ['\\x0b', '\\r', '\\x0e'], ['\\x0f', '\\t', '\\x0c'], ['\\x10', '\\x0f', '\\x0c'], ['\\x0b', '\\x0c', '\\x10'], ['\\x06', '\\x01', '\\x04'], ['\\x01', '\\x02', '\\x03'], ['\\x05', '\\x08', '\\x01'], ['\\x07', '\\x08', '\\x06'], ['\\x05', '\\x03', '\\x02'], ['\\x02', '\\x03', '\\x05'], ['\\x06', '\\x04', '\\x07'], ['\\x04', '\\x07', '\\x08'])\n",
      "(3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "N = 8\n",
    "sample = 0\n",
    "dataPath = \"Data/\"\n",
    "graph = json.load(open(dataPath + f\"3regularGraphs/N{N}/{sample}.json\"))\n",
    "M = graph[\"number_of_constraints\"]\n",
    "constraint_neighbours = graph[\"graph\"][\"constraint_neighbors\"]\n",
    "variable_neighbours = graph[\"graph\"][\"variable_neighbors\"]\n",
    "\n",
    "print(\"--------\")\n",
    "print('Constraints neighbors are :')\n",
    "print(constraint_neighbours)\n",
    "print('Variable neighbors are :')\n",
    "print(variable_neighbours)\n",
    "print(\"--------\")\n",
    "\n",
    "def generate_modes_in(constraint_neighbours, variable_neighbours):\n",
    "    # modes_str = [[str(variable) for variable in clause] for clause in constraint_neighbours]\n",
    "    # modes_for_variables_str = [[str(value+len(constraint_neighbours)) for value in array] for array in variable_neighbours]\n",
    "    # for array in variable_neighbours:\n",
    "    #     modes.append(array)\n",
    "    # print(modes_str)\n",
    "    \"\"\"À modifier: Modifier la notation de sindices des tenseurs pourque ce soit lisible pour cuQuantum.Network\"\"\"\n",
    "    all_neighbours = [[num+len(constraint_neighbours) for num in array] for array in constraint_neighbours]\n",
    "    for array in variable_neighbours:\n",
    "        all_neighbours.append(array)\n",
    "    for i, array in enumerate(all_neighbours):\n",
    "        print(f\"{i}, {array}\")\n",
    "    modes_in = tuple([num for num in array] for array in all_neighbours)\n",
    "    modes_in_chr = tuple([chr(num+1) for num in array] for array in all_neighbours)\n",
    "    num_modes_in = tuple(len(neighbours) for neighbours in all_neighbours)\n",
    "    ids_dict = {}\n",
    "    count = 0\n",
    "    expr = \"\"\n",
    "    start = 0x0100\n",
    "    end = start + 2*len(constraint_neighbours)\n",
    "    for key, unicode in enumerate(range(start, end)):\n",
    "        ids_dict[key] = chr(unicode)\n",
    "    for array in modes_in:\n",
    "        for value in array:\n",
    "            expr += ids_dict[value]\n",
    "        count += 1\n",
    "        if count < len(modes_in):\n",
    "            expr += \",\"\n",
    "    \n",
    "    return expr, modes_in_chr, num_modes_in # first half of modes is for the constraint tensors and the other is for the variable tensors\n",
    "\n",
    "def generate_extents(nb_variables, dim=2, k=3):\n",
    "    nb_tensors = 2 * nb_variables\n",
    "    extents = tuple((dim,) * k for _ in range(nb_tensors))\n",
    "    return extents\n",
    "\n",
    "def xorTensor(var_dim=2, k=3):\n",
    "    dims = (var_dim,) * k\n",
    "    tensor = np.zeros(dims, dtype = float)\n",
    "    for variable_ijk in range(var_dim**k):\n",
    "        c = np.unravel_index(variable_ijk, dims) # Gives index of tensor\n",
    "        if np.sum(c) % 2 == 1:\n",
    "            tensor[c] = 1\n",
    "    return tensor\n",
    "\n",
    "def copyTensor(var_dim=2, k=3):\n",
    "    dims = (var_dim,) * k\n",
    "    tensor = np.zeros(dims, dtype = float)\n",
    "    tensor[np.diag_indices(var_dim, k)] = 1\n",
    "    return tensor\n",
    "\n",
    "def tensors_initialization(nb_variables):\n",
    "    nb_constraints = nb_variables\n",
    "    tensors = []\n",
    "    for _ in range(nb_constraints):\n",
    "        tensors.append(xorTensor())\n",
    "    for _ in range(nb_variables):\n",
    "        tensors.append(copyTensor())\n",
    "    return tensors\n",
    "\n",
    "# def buildTensorNetwork(tensors_indices, tensors_list):\n",
    "#     return cuquantum.Network(tensors_indices, tensors_list)\n",
    "\n",
    "expr, modes_in, num_modes_in = generate_modes_in(constraint_neighbours, variable_neighbours)\n",
    "# # tn = buildTensorNetwork(expr, )\n",
    "print(expr)\n",
    "print(modes_in)\n",
    "print(num_modes_in)\n",
    "# a = np.array([[1,2],[3,4]])\n",
    "# b = np.array([[4,3],[2,1]])\n",
    "# # c = np.einsum('\\x01\\x02, \\x02\\x01', a, b)\n",
    "# # c = np.einsum('ij,ji', a, b)\n",
    "# a = np.array([0,1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tenxorsatCuQuantum' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tenxorsatCuQuantum ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Show the GPU that is used for the code\n",
    "########################################\n",
    "print(\"cuTensorNet-vers:\", cutn.get_version())\n",
    "dev = cp.cuda.Device()  # get current device\n",
    "props = cp.cuda.runtime.getDeviceProperties(dev.id)\n",
    "print(\"===== device info ======\")\n",
    "print(\"GPU-name:\", props[\"name\"].decode())\n",
    "print(\"GPU-clock:\", props[\"clockRate\"])\n",
    "print(\"GPU-memoryClock:\", props[\"memoryClockRate\"])\n",
    "print(\"GPU-nSM:\", props[\"multiProcessorCount\"])\n",
    "print(\"GPU-major:\", props[\"major\"])\n",
    "print(\"GPU-minor:\", props[\"minor\"])\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tenxorsatCuQuantum' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tenxorsatCuQuantum ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "######################################################################################\n",
    "# Computing: R_{k,l} = A_{a,b,c,d,e,f} B_{b,g,h,e,i,j} C_{m,a,g,f,i,k} D_{l,c,h,d,j,m}\n",
    "######################################################################################\n",
    "\n",
    "print(\"Include headers and define data types.\")\n",
    "\n",
    "data_type = cuquantum.cudaDataType.CUDA_R_32F\n",
    "compute_type = cuquantum.ComputeType.COMPUTE_32F\n",
    "num_inputs = 4\n",
    "\n",
    "# Create an array of modes\n",
    "modes_A = [ord(c) for c in ('a','b','c','d','e','f')]\n",
    "modes_B = [ord(c) for c in ('b','g','h','e','i','j')]\n",
    "modes_C = [ord(c) for c in ('m','a','g','f','i','k')]\n",
    "modes_D = [ord(c) for c in ('l','c','h','d','j','m')]\n",
    "modes_R = [ord(c) for c in ('k','l')]\n",
    "\n",
    "# Create an array of extents (shapes) for each tensor\n",
    "dim = 8\n",
    "extent_A = (dim,) * 6 \n",
    "extent_B = (dim,) * 6 \n",
    "extent_C = (dim,) * 6 \n",
    "extent_D = (dim,) * 6 \n",
    "extent_R = (dim,) * 2\n",
    "\n",
    "print(\"Define network, modes, and extents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tenxorsatCuQuantum' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tenxorsatCuQuantum ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Initialize data\n",
    "#################\n",
    "\n",
    "A_d = cp.random.random((np.prod(extent_A),), dtype=np.float32)\n",
    "B_d = cp.random.random((np.prod(extent_B),), dtype=np.float32)\n",
    "C_d = cp.random.random((np.prod(extent_C),), dtype=np.float32)\n",
    "D_d = cp.random.random((np.prod(extent_D),), dtype=np.float32)\n",
    "R_d = cp.zeros((np.prod(extent_R),), dtype=np.float32)\n",
    "raw_data_in_d = (A_d.data.ptr, B_d.data.ptr, C_d.data.ptr, D_d.data.ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tenxorsatCuQuantum' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tenxorsatCuQuantum ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# cuTensorNet\n",
    "#############\n",
    "\n",
    "stream = cp.cuda.Stream()\n",
    "handle = cutn.create()\n",
    "\n",
    "nmode_A = len(modes_A)\n",
    "nmode_B = len(modes_B)\n",
    "nmode_C = len(modes_C)\n",
    "nmode_D = len(modes_D)\n",
    "nmode_R = len(modes_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tenxorsatCuQuantum' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tenxorsatCuQuantum ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# Create Contraction Descriptor\n",
    "###############################\n",
    "\n",
    "modes_in = (modes_A, modes_B, modes_C, modes_D)\n",
    "extents_in = (extent_A, extent_B, extent_C, extent_D)\n",
    "num_modes_in = (nmode_A, nmode_B, nmode_C, nmode_D)\n",
    "\n",
    "# Strides are optional; if no stride (0) is provided, then cuTensorNet assumes a generalized column-major data layout\n",
    "strides_in = (0, 0, 0, 0)\n",
    "\n",
    "# Set up the tensor qualifiers for all input tensors\n",
    "qualifiers_in = np.zeros(num_inputs, dtype=cutn.tensor_qualifiers_dtype)\n",
    "\n",
    "# Set up tensor network\n",
    "desc_net = cutn.create_network_descriptor(handle,\n",
    "    num_inputs, num_modes_in, extents_in, strides_in, modes_in, qualifiers_in,  # inputs\n",
    "    nmode_R, extent_R, 0, modes_R,  # output\n",
    "    data_type, compute_type)\n",
    "\n",
    "print(\"Initialize the cuTensorNet library and create a network descriptor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tenxorsatCuQuantum' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tenxorsatCuQuantum ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "# Choose workspace limit based on available resources\n",
    "#####################################################\n",
    "\n",
    "free_mem, total_mem = dev.mem_info\n",
    "workspace_limit = int(free_mem * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tenxorsatCuQuantum' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tenxorsatCuQuantum ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# Find \"optimal\" contraction order and slicing\n",
    "##############################################\n",
    "\n",
    "optimizer_config = cutn.create_contraction_optimizer_config(handle)\n",
    "\n",
    "# Set the value of the partitioner imbalance factor to 30 (if desired)\n",
    "imbalance_dtype = cutn.contraction_optimizer_config_get_attribute_dtype(\n",
    "    cutn.ContractionOptimizerConfigAttribute.GRAPH_IMBALANCE_FACTOR)\n",
    "imbalance_factor = np.asarray((30,), dtype=imbalance_dtype)\n",
    "cutn.contraction_optimizer_config_set_attribute(\n",
    "    handle, optimizer_config, cutn.ContractionOptimizerConfigAttribute.GRAPH_IMBALANCE_FACTOR,\n",
    "    imbalance_factor.ctypes.data, imbalance_factor.dtype.itemsize)\n",
    "\n",
    "optimizer_info = cutn.create_contraction_optimizer_info(handle, desc_net)\n",
    "\n",
    "cutn.contraction_optimize(handle, desc_net, optimizer_config, workspace_limit, optimizer_info)\n",
    "\n",
    "num_slices_dtype = cutn.contraction_optimizer_info_get_attribute_dtype(\n",
    "    cutn.ContractionOptimizerInfoAttribute.NUM_SLICES)\n",
    "num_slices = np.zeros((1,), dtype=num_slices_dtype)\n",
    "cutn.contraction_optimizer_info_get_attribute(\n",
    "    handle, optimizer_info, cutn.ContractionOptimizerInfoAttribute.NUM_SLICES,\n",
    "    num_slices.ctypes.data, num_slices.dtype.itemsize)\n",
    "num_slices = int(num_slices)\n",
    "\n",
    "assert num_slices > 0\n",
    "\n",
    "print(\"Find an optimized contraction path with cuTensorNet optimizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tenxorsatCuQuantum' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tenxorsatCuQuantum ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "# Initialize all pair-wise contraction plans (for cuTENSOR)\n",
    "###########################################################\n",
    "\n",
    "work_desc = cutn.create_workspace_descriptor(handle)\n",
    "cutn.workspace_compute_contraction_sizes(handle, desc_net, optimizer_info, work_desc)\n",
    "required_workspace_size = cutn.workspace_get_size(\n",
    "    handle, work_desc,\n",
    "    cutn.WorksizePref.MIN,\n",
    "    cutn.Memspace.DEVICE)\n",
    "work = cp.cuda.alloc(required_workspace_size)\n",
    "cutn.workspace_set(\n",
    "    handle, work_desc,\n",
    "    cutn.Memspace.DEVICE,\n",
    "    work.ptr, required_workspace_size)\n",
    "plan = cutn.create_contraction_plan(handle, desc_net, optimizer_info, work_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tenxorsatCuQuantum' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tenxorsatCuQuantum ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "# Optional: Auto-tune cuTENSOR's cutensorContractionPlan to pick the fastest kernel\n",
    "###################################################################################\n",
    "\n",
    "pref = cutn.create_contraction_autotune_preference(handle)\n",
    "\n",
    "num_autotuning_iterations = 5 # may be 0\n",
    "n_iter_dtype = cutn.contraction_autotune_preference_get_attribute_dtype(\n",
    "    cutn.ContractionAutotunePreferenceAttribute.MAX_ITERATIONS)\n",
    "num_autotuning_iterations = np.asarray([num_autotuning_iterations], dtype=n_iter_dtype)\n",
    "cutn.contraction_autotune_preference_set_attribute(\n",
    "    handle, pref,\n",
    "    cutn.ContractionAutotunePreferenceAttribute.MAX_ITERATIONS,\n",
    "    num_autotuning_iterations.ctypes.data, num_autotuning_iterations.dtype.itemsize)\n",
    "\n",
    "# Modify the plan again to find the best pair-wise contractions\n",
    "cutn.contraction_autotune(\n",
    "    handle, plan, raw_data_in_d, R_d.data.ptr,\n",
    "    work_desc, pref, stream.ptr)\n",
    "\n",
    "cutn.destroy_contraction_autotune_preference(pref)\n",
    " \n",
    "print(\"Create a contraction plan for cuTENSOR and optionally auto-tune it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tenxorsatCuQuantum' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tenxorsatCuQuantum ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# Execution\n",
    "###########\n",
    "\n",
    "minTimeCUTENSOR = 1e100\n",
    "num_runs = 3  # to get stable perf results\n",
    "e1 = cp.cuda.Event()\n",
    "e2 = cp.cuda.Event()\n",
    "slice_group = cutn.create_slice_group_from_id_range(handle, 0, num_slices, 1)\n",
    "\n",
    "for i in range(num_runs):\n",
    "    # Contract over all slices.\n",
    "    # A user may choose to parallelize over the slices across multiple devices.\n",
    "    e1.record()\n",
    "    cutn.contract_slices(\n",
    "        handle, plan, raw_data_in_d, R_d.data.ptr, False,\n",
    "        work_desc, slice_group, stream.ptr)\n",
    "    e2.record()\n",
    "\n",
    "    # Synchronize and measure timing\n",
    "    e2.synchronize()\n",
    "    time = cp.cuda.get_elapsed_time(e1, e2) / 1000  # ms -> s\n",
    "    minTimeCUTENSOR = minTimeCUTENSOR if minTimeCUTENSOR < time else time\n",
    "\n",
    "print(\"Contract the network, each slice uses the same contraction plan.\")\n",
    "\n",
    "# free up the workspace\n",
    "del work\n",
    "\n",
    "# Recall that we set strides to null (0), so the data are in F-contiguous layout\n",
    "A_d = A_d.reshape(extent_A, order='F')\n",
    "B_d = B_d.reshape(extent_B, order='F')\n",
    "C_d = C_d.reshape(extent_C, order='F')\n",
    "D_d = D_d.reshape(extent_D, order='F')\n",
    "R_d = R_d.reshape(extent_R, order='F')\n",
    "path, _ = cuquantum.einsum_path(\"abcdef,bgheij,magfik,lchdjm->kl\", A_d, B_d, C_d, D_d)\n",
    "out = cp.einsum(\"abcdef,bgheij,magfik,lchdjm->kl\", A_d, B_d, C_d, D_d, optimize=path)\n",
    "if not cp.allclose(out, R_d):\n",
    "    raise RuntimeError(\"result is incorrect\")\n",
    "print(\"Check cuTensorNet result against that of cupy.einsum().\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tenxorsatCuQuantum' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tenxorsatCuQuantum ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "\n",
    "flops_dtype = cutn.contraction_optimizer_info_get_attribute_dtype(\n",
    "    cutn.ContractionOptimizerInfoAttribute.FLOP_COUNT)\n",
    "flops = np.zeros((1,), dtype=flops_dtype)\n",
    "cutn.contraction_optimizer_info_get_attribute(\n",
    "    handle, optimizer_info, cutn.ContractionOptimizerInfoAttribute.FLOP_COUNT,\n",
    "    flops.ctypes.data, flops.dtype.itemsize)\n",
    "flops = float(flops)\n",
    "\n",
    "print(f\"num_slices: {num_slices}\")\n",
    "print(f\"{minTimeCUTENSOR * 1000 / num_slices} ms / slice\")\n",
    "print(f\"{flops / 1e9 / minTimeCUTENSOR} GFLOPS/s\")\n",
    "\n",
    "cutn.destroy_slice_group(slice_group)\n",
    "cutn.destroy_contraction_plan(plan)\n",
    "cutn.destroy_contraction_optimizer_info(optimizer_info)\n",
    "cutn.destroy_contraction_optimizer_config(optimizer_config)\n",
    "cutn.destroy_network_descriptor(desc_net)\n",
    "cutn.destroy_workspace_descriptor(work_desc)\n",
    "cutn.destroy(handle)\n",
    "\n",
    "print(\"Free resource and exit.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_first_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "476da5f4a04e2fd42abcc34b0501a3a8e771f7aa6605076b992968a2259c8497"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
